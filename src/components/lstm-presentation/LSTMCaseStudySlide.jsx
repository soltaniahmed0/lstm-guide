import React, { useState } from 'react'
import './LSTMCaseStudySlide.css'

function LSTMCaseStudySlide() {
  const [currentStep, setCurrentStep] = useState(0)

  const codeSteps = [
    {
      step: 0,
      title: '1. Importation des Biblioth√®ques',
      code: `import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout`,
      explanation: 'Importation des biblioth√®ques n√©cessaires pour le traitement des donn√©es et la cr√©ation du mod√®le LSTM.',
      math: null,
      mathExplanation: null
    },
    {
      step: 1,
      title: '2. Chargement et Pr√©paration des Donn√©es',
      code: `# Charger les donn√©es
data = pd.read_csv('gold_price.csv')
prices = data['Price'].values.reshape(-1, 1)

# Normalisation (Min-Max Scaling)
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_prices = scaler.fit_transform(prices)`,
      explanation: 'Les donn√©es sont normalis√©es entre 0 et 1 pour am√©liorer la convergence du mod√®le et √©viter les probl√®mes num√©riques.',
      math: 'x<sub>scaled</sub> = (x - x<sub>min</sub>) / (x<sub>max</sub> - x<sub>min</sub>)',
      mathExplanation: 'Normalisation Min-Max : transforme les valeurs dans l\'intervalle [0, 1]. Cela permet d\'√©viter que certaines features dominent les autres et am√©liore la stabilit√© de l\'entra√Ænement.'
    },
    {
      step: 2,
      title: '3. Cr√©ation des S√©quences',
      code: `def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length])
    return np.array(X), np.array(y)

seq_length = 60  # 60 jours de donn√©es
X_train, y_train = create_sequences(scaled_prices, seq_length)`,
      explanation: 'Cr√©ation de s√©quences de 60 jours pour pr√©dire le jour suivant. Chaque s√©quence X contient 60 valeurs cons√©cutives, y contient la valeur suivante.',
      math: 'X[i] = [x<sub>i</sub>, x<sub>i+1</sub>, ..., x<sub>i+59</sub>]\ny[i] = x<sub>i+60</sub>',
      mathExplanation: 'Pour chaque position i, on prend 60 valeurs cons√©cutives comme entr√©e (X[i]) et la 61√®me valeur comme sortie (y[i]). Cela cr√©e un dataset supervis√© pour l\'entra√Ænement.'
    },
    {
      step: 3,
      title: '4. Architecture du Mod√®le LSTM',
      code: `model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(60, 1)),
    Dropout(0.2),
    LSTM(50, return_sequences=True),
    Dropout(0.2),
    LSTM(50),
    Dropout(0.2),
    Dense(1)
])`,
      explanation: 'Mod√®le avec 3 couches LSTM de 50 neurones chacune, avec Dropout pour √©viter le surapprentissage. Chaque couche LSTM applique les formules vues pr√©c√©demment.',
      math: 'h<sub>t</sub><sup>(l)</sup> = LSTM(h<sub>t-1</sub><sup>(l)</sup>, x<sub>t</sub><sup>(l)</sup>, C<sub>t-1</sub><sup>(l)</sup>)',
      mathExplanation: 'Chaque couche LSTM applique les formules LSTM (Forget Gate, Input Gate, Cell State, Output Gate). Le Dropout d√©sactive al√©atoirement 20% des neurones pendant l\'entra√Ænement pour r√©duire le surapprentissage.'
    },
    {
      step: 4,
      title: '5. Compilation et Entra√Ænement',
      code: `model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=100, batch_size=32)`,
      explanation: 'Le mod√®le est entra√Æn√© avec l\'optimiseur Adam et la fonction de perte MSE. Adam adapte le taux d\'apprentissage pour chaque param√®tre.',
      math: 'Loss = (1/n) Œ£(y<sub>pred</sub> - y<sub>true</sub>)¬≤',
      mathExplanation: 'Mean Squared Error : moyenne des carr√©s des diff√©rences entre pr√©dictions et valeurs r√©elles. Adam optimise les poids (W<sub>f</sub>, W<sub>i</sub>, W<sub>C</sub>, W<sub>o</sub>) pour minimiser cette erreur via la r√©tropropagation.'
    },
    {
      step: 5,
      title: '6. Pr√©diction',
      code: `# Pr√©dire les prix futurs
predictions = model.predict(X_test)
predicted_prices = scaler.inverse_transform(predictions)`,
      explanation: 'Les pr√©dictions sont faites sur les donn√©es de test, puis d√©normalis√©es pour obtenir les prix r√©els en dollars.',
      math: 'x<sub>original</sub> = x<sub>scaled</sub> √ó (x<sub>max</sub> - x<sub>min</sub>) + x<sub>min</sub>',
      mathExplanation: 'D√©normalisation inverse : on revient aux valeurs originales des prix en multipliant par l\'amplitude et en ajoutant le minimum.'
    },
    {
      step: 6,
      title: '7. √âvaluation',
      code: `from sklearn.metrics import mean_absolute_error, r2_score

mae = mean_absolute_error(y_true, predicted_prices)
r2 = r2_score(y_true, predicted_prices)
accuracy = (1 - mae/mean_price) * 100  # ~96%`,
      explanation: 'Calcul de la pr√©cision : 96% signifie que l\'erreur moyenne est de 4% par rapport au prix moyen. R¬≤ mesure la qualit√© de l\'ajustement.',
      math: 'Accuracy = (1 - MAE / mean_price) √ó 100%\nMAE = (1/n) Œ£|y<sub>pred</sub> - y<sub>true</sub>|',
      mathExplanation: 'MAE (Mean Absolute Error) mesure l\'erreur moyenne absolue. L\'accuracy est calcul√©e comme le compl√©ment de l\'erreur relative. R¬≤ mesure la proportion de variance expliqu√©e (proche de 1 = excellent).'
    }
  ]

  const currentStepData = codeSteps[currentStep]

  return (
    <div className="slide lstm-case-study-slide">
      <h1 className="slide-title-main">√âtude de Cas : Pr√©diction du Prix de l'Or</h1>
      <p className="case-study-source">
        Source : <a href="https://www.kaggle.com/code/farzadnekouei/gold-price-prediction-lstm-96-accuracy" target="_blank" rel="noopener noreferrer">
          Kaggle - Gold Price Prediction LSTM (96% Accuracy)
        </a>
      </p>

      <div className="case-study-container">
        <div className="code-section">
          <div className="step-header">
            <h3>{currentStepData.title}</h3>
            <div className="step-navigation">
              <button
                className="nav-btn-small"
                onClick={() => setCurrentStep(Math.max(0, currentStep - 1))}
                disabled={currentStep === 0}
              >
                ‚Üê
              </button>
              <span className="step-counter">{currentStep + 1} / {codeSteps.length}</span>
              <button
                className="nav-btn-small"
                onClick={() => setCurrentStep(Math.min(codeSteps.length - 1, currentStep + 1))}
                disabled={currentStep === codeSteps.length - 1}
              >
                ‚Üí
              </button>
            </div>
          </div>

          <div className="code-box">
            <pre><code>{currentStepData.code}</code></pre>
          </div>

          <div className="explanation-box">
            <h4>üí° Explication :</h4>
            <p>{currentStepData.explanation}</p>
          </div>
        </div>

        {currentStepData.math && (
          <div className="math-section">
            <h3>üìê Formules Math√©matiques :</h3>
            <div className="math-box">
              <p className="math-formula" dangerouslySetInnerHTML={{ __html: `<strong>${currentStepData.math}</strong>` }}></p>
              {currentStepData.mathExplanation && (
                <p className="math-explanation" dangerouslySetInnerHTML={{ __html: currentStepData.mathExplanation }}></p>
              )}
            </div>
          </div>
        )}
      </div>

      <div className="architecture-visualization">
        <h3>Architecture du Mod√®le :</h3>
        <div className="model-diagram">
          <div className="layer input-layer">
            <div className="layer-label">Input</div>
            <div className="layer-shape">(60, 1)</div>
          </div>
          <div className="arrow">‚Üí</div>
          <div className="layer lstm-layer">
            <div className="layer-label">LSTM(50)</div>
            <div className="layer-shape">50 neurones</div>
          </div>
          <div className="arrow">‚Üí</div>
          <div className="layer dropout-layer">
            <div className="layer-label">Dropout(0.2)</div>
          </div>
          <div className="arrow">‚Üí</div>
          <div className="layer lstm-layer">
            <div className="layer-label">LSTM(50)</div>
            <div className="layer-shape">50 neurones</div>
          </div>
          <div className="arrow">‚Üí</div>
          <div className="layer dropout-layer">
            <div className="layer-label">Dropout(0.2)</div>
          </div>
          <div className="arrow">‚Üí</div>
          <div className="layer lstm-layer">
            <div className="layer-label">LSTM(50)</div>
            <div className="layer-shape">50 neurones</div>
          </div>
          <div className="arrow">‚Üí</div>
          <div className="layer dropout-layer">
            <div className="layer-label">Dropout(0.2)</div>
          </div>
          <div className="arrow">‚Üí</div>
          <div className="layer output-layer">
            <div className="layer-label">Dense(1)</div>
            <div className="layer-shape">Prix pr√©dit</div>
          </div>
        </div>
      </div>
    </div>
  )
}

export default LSTMCaseStudySlide
